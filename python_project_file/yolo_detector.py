"""
yolo_detector.py - ê°œì„ ëœ YOLO ê°ì²´ ì¸ì‹ ì‹œìŠ¤í…œ

ì£¼ìš” ê°œì„ ì‚¬í•­:
- ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ (ì¤‘ìš”!)
- GPU/CPU ìë™ ì„ íƒ
- ì„±ëŠ¥ ìµœì í™”
- ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
- ë¦¬ì†ŒìŠ¤ ì•ˆì „ ê´€ë¦¬
- ê°ì²´ ì¶”ì  ê¸°ëŠ¥
- ì¢Œí‘œ ë³€í™˜ ê°œì„ 
"""

import cv2
import numpy as np
import threading
import time
import logging
import atexit
from typing import List, Dict, Optional, Tuple, Any, Callable
from pathlib import Path
import queue
from contextlib import contextmanager
import gc

# YOLOv8 import (ì„¤ì¹˜ë˜ì–´ ìˆëŠ” ê²½ìš°)
try:
    from ultralytics import YOLO
    import torch
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("âš ï¸ YOLO ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")

logger = logging.getLogger(__name__)

# ========== ë°ì´í„° í´ë˜ìŠ¤ ==========

class DetectedObject:
    """ê°ì§€ëœ ê°ì²´ ì •ë³´"""
    
    def __init__(self, class_name: str, confidence: float, bbox: Tuple[int, int, int, int],
                 center: Tuple[int, int], area: float, timestamp: float = None):
        self.class_name = class_name
        self.confidence = confidence
        self.bbox = bbox  # (x1, y1, x2, y2)
        self.center = center  # (x, y)
        self.area = area
        self.timestamp = timestamp or time.time()
        self.id: Optional[int] = None  # ê°ì²´ ì¶”ì ìš© ID
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'class_name': self.class_name,
            'confidence': self.confidence,
            'bbox': self.bbox,
            'center': self.center,
            'area': self.area,
            'timestamp': self.timestamp,
            'id': self.id
        }
    
    def get_robot_coordinates(self, calibration_matrix: np.ndarray = None) -> Tuple[float, float]:
        """ë¡œë´‡ ì¢Œí‘œê³„ë¡œ ë³€í™˜"""
        if calibration_matrix is not None:
            # ì‹¤ì œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ì‚¬ìš©í•œ ë³€í™˜
            cam_point = np.array([self.center[0], self.center[1], 1])
            robot_point = calibration_matrix @ cam_point
            return float(robot_point[0]), float(robot_point[1])
        else:
            # ê°„ë‹¨í•œ ìŠ¤ì¼€ì¼ë§ ë³€í™˜ (ì˜ˆì‹œ)
            # ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ì‚¬ìš©
            x_scale = 800 / 640  # ì˜ˆì‹œ ê°’
            y_scale = 600 / 480  # ì˜ˆì‹œ ê°’
            x_offset = 200       # ì˜ˆì‹œ ê°’
            y_offset = 0         # ì˜ˆì‹œ ê°’
            
            robot_x = (self.center[0] - 320) * x_scale + x_offset
            robot_y = (240 - self.center[1]) * y_scale + y_offset
            
            return robot_x, robot_y

# ========== YOLO ê°ì§€ê¸° í´ë˜ìŠ¤ ==========

class YOLODetector:
    """ê°œì„ ëœ YOLO ê°ì²´ ê°ì§€ê¸°"""
    
    def __init__(self, model_name: str = 'yolov8n.pt', 
                 device: str = 'auto',
                 confidence_threshold: float = 0.5,
                 target_classes: List[str] = None):
        
        self.model_name = model_name
        self.confidence_threshold = confidence_threshold
        self.target_classes = target_classes or ['chair', 'couch', 'bed', 'dining table']
        
        # ëª¨ë¸ ë° ìƒíƒœ ê´€ë¦¬
        self.model: Optional[Any] = None
        self.device = self._determine_device(device)
        self.is_initialized = False
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.detection_count = 0
        self.last_detection_time = 0
        self.avg_inference_time = 0
        
        # ê°ì²´ ì¶”ì 
        self.tracked_objects: Dict[int, DetectedObject] = {}
        self.next_object_id = 1
        
        # ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
        self._cleanup_registered = False
        
        logger.info(f"YOLODetector ì´ˆê¸°í™”: ëª¨ë¸={model_name}, ë””ë°”ì´ìŠ¤={self.device}")
    
    def _determine_device(self, device: str) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ"""
        if device == 'auto':
            if YOLO_AVAILABLE and torch.cuda.is_available():
                logger.info("CUDA GPU ê°ì§€ë¨. GPU ì‚¬ìš©")
                return 'cuda'
            else:
                logger.info("GPU ë¯¸ì‚¬ìš© ë˜ëŠ” ë¯¸ê°ì§€. CPU ì‚¬ìš©")
                return 'cpu'
        return device
    
    def initialize(self) -> bool:
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        if self.is_initialized:
            return True
        
        if not YOLO_AVAILABLE:
            logger.warning("YOLO ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ. ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘")
            self.is_initialized = True
            return True
        
        try:
            logger.info(f"YOLO ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_name}")
            
            # ëª¨ë¸ ë¡œë“œ
            self.model = YOLO(self.model_name)
            
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            if hasattr(self.model, 'to'):
                self.model.to(self.device)
            
            # ëª¨ë¸ ìµœì í™” (ì¶”ë¡  ì†ë„ í–¥ìƒ)
            if hasattr(self.model, 'fuse'):
                self.model.fuse()
            
            # ì›Œë°ì—… ì¶”ë¡  (ì²« ë²ˆì§¸ ì¶”ë¡ ì€ ëŠë¦¼)
            dummy_image = np.zeros((640, 640, 3), dtype=np.uint8)
            self._run_inference(dummy_image)
            
            self.is_initialized = True
            
            # ğŸ”¥ ìë™ ì •ë¦¬ ë“±ë¡ (ì¤‘ìš”!)
            if not self._cleanup_registered:
                atexit.register(self.cleanup)
                self._cleanup_registered = True
            
            logger.info("YOLO ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"YOLO ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _run_inference(self, image: np.ndarray) -> List[DetectedObject]:
        """ì¶”ë¡  ì‹¤í–‰"""
        if not YOLO_AVAILABLE or self.model is None:
            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
            return self._simulate_detection(image)
        
        start_time = time.time()
        
        try:
            # YOLO ì¶”ë¡  ì‹¤í–‰
            results = self.model(image, conf=self.confidence_threshold, verbose=False)
            
            # ê²°ê³¼ íŒŒì‹±
            detected_objects = []
            
            for result in results:
                if hasattr(result, 'boxes') and result.boxes is not None:
                    boxes = result.boxes
                    
                    for i in range(len(boxes)):
                        # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
                        x1, y1, x2, y2 = boxes.xyxy[i].cpu().numpy()
                        
                        # ì‹ ë¢°ë„
                        confidence = float(boxes.conf[i].cpu().numpy())
                        
                        # í´ë˜ìŠ¤ ID ë° ì´ë¦„
                        class_id = int(boxes.cls[i].cpu().numpy())
                        class_name = self.model.names[class_id]
                        
                        # íƒ€ê²Ÿ í´ë˜ìŠ¤ í•„í„°ë§
                        if class_name not in self.target_classes:
                            continue
                        
                        # ì¤‘ì‹¬ì  ë° ë©´ì  ê³„ì‚°
                        center_x = int((x1 + x2) / 2)
                        center_y = int((y1 + y2) / 2)
                        area = (x2 - x1) * (y2 - y1)
                        
                        # DetectedObject ìƒì„±
                        obj = DetectedObject(
                            class_name=class_name,
                            confidence=confidence,
                            bbox=(int(x1), int(y1), int(x2), int(y2)),
                            center=(center_x, center_y),
                            area=area
                        )
                        
                        detected_objects.append(obj)
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            inference_time = time.time() - start_time
            self._update_performance_stats(inference_time)
            
            return detected_objects
            
        except Exception as e:
            logger.error(f"YOLO ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return []
    
    def _simulate_detection(self, image: np.ndarray) -> List[DetectedObject]:
        """ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ê°ì§€"""
        height, width = image.shape[:2]
        
        # ê°€ì§œ ê°ì²´ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
        simulated_objects = []
        
        if self.detection_count % 30 == 0:  # 1ì´ˆì— í•œ ë²ˆ ì •ë„ ê°ì§€ (30fps ê¸°ì¤€)
            # ê°€ìš´ë° ê·¼ì²˜ì— ì˜ì ê°ì§€ ì‹œë®¬ë ˆì´ì…˜
            center_x = width // 2 + np.random.randint(-50, 50)
            center_y = height // 2 + np.random.randint(-50, 50)
            
            bbox_width = 80
            bbox_height = 100
            
            obj = DetectedObject(
                class_name='chair',
                confidence=0.85,
                bbox=(center_x - bbox_width//2, center_y - bbox_height//2,
                     center_x + bbox_width//2, center_y + bbox_height//2),
                center=(center_x, center_y),
                area=bbox_width * bbox_height
            )
            
            simulated_objects.append(obj)
        
        return simulated_objects
    
    def _update_performance_stats(self, inference_time: float):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.detection_count += 1
        self.last_detection_time = time.time()
        
        # ì´ë™ í‰ê· ìœ¼ë¡œ ì¶”ë¡  ì‹œê°„ ê³„ì‚°
        alpha = 0.1
        self.avg_inference_time = (alpha * inference_time + 
                                 (1 - alpha) * self.avg_inference_time)
    
    def detect_objects(self, image: np.ndarray) -> List[DetectedObject]:
        """ê°ì²´ ê°ì§€ ë©”ì¸ í•¨ìˆ˜"""
        if not self.is_initialized:
            if not self.initialize():
                return []
        
        detected_objects = self._run_inference(image)
        
        # ê°ì²´ ì¶”ì  ì—…ë°ì´íŠ¸
        if detected_objects:
            self._update_object_tracking(detected_objects)
        
        return detected_objects
    
    def _update_object_tracking(self, detected_objects: List[DetectedObject]):
        """ê°ì²´ ì¶”ì  ì—…ë°ì´íŠ¸"""
        # ê°„ë‹¨í•œ ì¶”ì  ì•Œê³ ë¦¬ì¦˜ (ì¤‘ì‹¬ì  ê¸°ë°˜)
        tracking_threshold = 100  # í”½ì…€ ê±°ë¦¬
        
        for obj in detected_objects:
            best_match_id = None
            best_distance = float('inf')
            
            # ê¸°ì¡´ ì¶”ì  ê°ì²´ì™€ ë§¤ì¹­
            for track_id, tracked_obj in self.tracked_objects.items():
                distance = np.sqrt((obj.center[0] - tracked_obj.center[0])**2 + 
                                 (obj.center[1] - tracked_obj.center[1])**2)
                
                if distance < tracking_threshold and distance < best_distance:
                    best_distance = distance
                    best_match_id = track_id
            
            if best_match_id is not None:
                # ê¸°ì¡´ ê°ì²´ ì—…ë°ì´íŠ¸
                obj.id = best_match_id
                self.tracked_objects[best_match_id] = obj
            else:
                # ìƒˆ ê°ì²´ ì¶”ê°€
                obj.id = self.next_object_id
                self.tracked_objects[self.next_object_id] = obj
                self.next_object_id += 1
        
        # ì˜¤ë˜ëœ ì¶”ì  ê°ì²´ ì œê±°
        current_time = time.time()
        ids_to_remove = []
        
        for track_id, tracked_obj in self.tracked_objects.items():
            if current_time - tracked_obj.timestamp > 5.0:  # 5ì´ˆ í›„ ì œê±°
                ids_to_remove.append(track_id)
        
        for track_id in ids_to_remove:
            del self.tracked_objects[track_id]
    
    def get_best_target(self, preferred_class: str = None) -> Optional[DetectedObject]:
        """ê°€ì¥ ì í•©í•œ íƒ€ê²Ÿ ê°ì²´ ë°˜í™˜"""
        if not self.tracked_objects:
            return None
        
        # ì„ í˜¸ í´ë˜ìŠ¤ê°€ ìˆìœ¼ë©´ í•´ë‹¹ í´ë˜ìŠ¤ ìš°ì„ 
        candidates = list(self.tracked_objects.values())
        
        if preferred_class:
            preferred_candidates = [obj for obj in candidates 
                                  if obj.class_name == preferred_class]
            if preferred_candidates:
                candidates = preferred_candidates
        
        # ì‹ ë¢°ë„ê°€ ê°€ì¥ ë†’ì€ ê°ì²´ ì„ íƒ
        best_object = max(candidates, key=lambda obj: obj.confidence)
        return best_object
    
    def get_performance_info(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ì •ë³´ ë°˜í™˜"""
        return {
            'detection_count': self.detection_count,
            'avg_inference_time': self.avg_inference_time,
            'last_detection_time': self.last_detection_time,
            'tracked_objects_count': len(self.tracked_objects),
            'device': self.device,
            'is_initialized': self.is_initialized
        }
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€"""
        logger.info("YOLO ê°ì§€ê¸° ì •ë¦¬ ì‹œì‘...")
        
        try:
            # ì¶”ì  ê°ì²´ ì •ë¦¬
            self.tracked_objects.clear()
            
            # ëª¨ë¸ ì •ë¦¬
            if self.model is not None:
                del self.model
                self.model = None
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if YOLO_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            self.is_initialized = False
            logger.info("YOLO ê°ì§€ê¸° ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"YOLO ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # Context Manager ì§€ì›
    def __enter__(self):
        self.initialize()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.cleanup()

# ========== ì¹´ë©”ë¼ ê´€ë¦¬ í´ë˜ìŠ¤ ==========

class CameraManager:
    """ì¹´ë©”ë¼ ê´€ë¦¬ í´ë˜ìŠ¤ - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€"""
    
    def __init__(self, camera_index: int = 0, 
                 resolution: Tuple[int, int] = (640, 480),
                 fps: int = 30):
        self.camera_index = camera_index
        self.resolution = resolution
        self.fps = fps
        
        self.cap: Optional[cv2.VideoCapture] = None
        self.is_opened = False
        self.frame_count = 0
        self.last_frame_time = 0
        
        # ìë™ ì •ë¦¬ ë“±ë¡
        atexit.register(self.release)
    
    def initialize(self) -> bool:
        """ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        try:
            self.cap = cv2.VideoCapture(self.camera_index)
            
            if not self.cap.isOpened():
                logger.error(f"ì¹´ë©”ë¼ {self.camera_index} ì—´ê¸° ì‹¤íŒ¨")
                return False
            
            # ì¹´ë©”ë¼ ì„¤ì •
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.resolution[0])
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.resolution[1])
            self.cap.set(cv2.CAP_PROP_FPS, self.fps)
            
            # ë²„í¼ í¬ê¸° ìµœì†Œí™” (ì§€ì—° ê°ì†Œ)
            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            
            self.is_opened = True
            logger.info(f"ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ: {self.resolution}@{self.fps}fps")
            return True
            
        except Exception as e:
            logger.error(f"ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def read_frame(self) -> Optional[np.ndarray]:
        """í”„ë ˆì„ ì½ê¸°"""
        if not self.is_opened or self.cap is None:
            return None
        
        try:
            ret, frame = self.cap.read()
            
            if ret:
                self.frame_count += 1
                self.last_frame_time = time.time()
                return frame
            else:
                logger.warning("í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            logger.error(f"í”„ë ˆì„ ì½ê¸° ì˜¤ë¥˜: {e}")
            return None
    
    def get_fps(self) -> float:
        """ì‹¤ì œ FPS ê³„ì‚°"""
        if self.frame_count < 2:
            return 0.0
        
        current_time = time.time()
        elapsed_time = current_time - (self.last_frame_time - self.frame_count / self.fps)
        
        if elapsed_time > 0:
            return self.frame_count / elapsed_time
        return 0.0
    
    def release(self):
        """ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ í•´ì œ"""
        try:
            if self.cap is not None:
                self.cap.release()
                self.cap = None
            
            self.is_opened = False
            logger.info("ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ í•´ì œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì¹´ë©”ë¼ í•´ì œ ì˜¤ë¥˜: {e}")
    
    # Context Manager ì§€ì›
    def __enter__(self):
        self.initialize()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.release()

# ========== í†µí•© ë¹„ì „ ì‹œìŠ¤í…œ ==========

class VisionSystem:
    """í†µí•© ë¹„ì „ ì‹œìŠ¤í…œ"""
    
    def __init__(self, camera_index: int = 0,
                 model_name: str = 'yolov8n.pt',
                 confidence_threshold: float = 0.5):
        
        self.camera_manager = CameraManager(camera_index)
        self.yolo_detector = YOLODetector(model_name, confidence_threshold=confidence_threshold)
        
        # ìƒíƒœ ê´€ë¦¬
        self.is_running = False
        self.detection_thread: Optional[threading.Thread] = None
        self.detection_queue = queue.Queue(maxsize=10)
        
        # ì½œë°± í•¨ìˆ˜ë“¤
        self.detection_callbacks: List[Callable[[List[DetectedObject]], None]] = []
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.total_frames = 0
        self.start_time = time.time()
        
        logger.info("VisionSystem ì´ˆê¸°í™” ì™„ë£Œ")
    
    def add_detection_callback(self, callback: Callable[[List[DetectedObject]], None]):
        """ê°ì§€ ê²°ê³¼ ì½œë°± ì¶”ê°€"""
        self.detection_callbacks.append(callback)
    
    def start(self) -> bool:
        """ë¹„ì „ ì‹œìŠ¤í…œ ì‹œì‘"""
        if self.is_running:
            return True
        
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        if not self.camera_manager.initialize():
            return False
        
        # YOLO ì´ˆê¸°í™”
        if not self.yolo_detector.initialize():
            return False
        
        # ê°ì§€ ìŠ¤ë ˆë“œ ì‹œì‘
        self.is_running = True
        self.detection_thread = threading.Thread(target=self._detection_loop, daemon=True)
        self.detection_thread.start()
        
        logger.info("ë¹„ì „ ì‹œìŠ¤í…œ ì‹œì‘ ì™„ë£Œ")
        return True
    
    def stop(self):
        """ë¹„ì „ ì‹œìŠ¤í…œ ì¤‘ì§€"""
        self.is_running = False
        
        if self.detection_thread:
            self.detection_thread.join(timeout=2.0)
        
        self.camera_manager.release()
        self.yolo_detector.cleanup()
        
        logger.info("ë¹„ì „ ì‹œìŠ¤í…œ ì¤‘ì§€ ì™„ë£Œ")
    
    def _detection_loop(self):
        """ê°ì§€ ë£¨í”„ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)"""
        logger.info("ê°ì§€ ë£¨í”„ ì‹œì‘")
        
        while self.is_running:
            try:
                # í”„ë ˆì„ ì½ê¸°
                frame = self.camera_manager.read_frame()
                if frame is None:
                    time.sleep(0.1)
                    continue
                
                # ê°ì²´ ê°ì§€
                detected_objects = self.yolo_detector.detect_objects(frame)
                
                # ê²°ê³¼ë¥¼ íì— ì¶”ê°€
                try:
                    self.detection_queue.put_nowait({
                        'frame': frame.copy(),
                        'objects': detected_objects,
                        'timestamp': time.time()
                    })
                except queue.Full:
                    # íê°€ ê°€ë“ ì°¬ ê²½ìš° ì˜¤ë˜ëœ ê²°ê³¼ ì œê±°
                    try:
                        self.detection_queue.get_nowait()
                        self.detection_queue.put_nowait({
                            'frame': frame.copy(),
                            'objects': detected_objects,
                            'timestamp': time.time()
                        })
                    except queue.Empty:
                        pass
                
                # ì½œë°± í˜¸ì¶œ
                for callback in self.detection_callbacks:
                    try:
                        callback(detected_objects)
                    except Exception as e:
                        logger.error(f"ê°ì§€ ì½œë°± ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                
                self.total_frames += 1
                
                # CPU ì‚¬ìš©ë¥  ì¡°ì ˆ
                time.sleep(0.033)  # ~30fps
                
            except Exception as e:
                logger.error(f"ê°ì§€ ë£¨í”„ ì˜¤ë¥˜: {e}")
                time.sleep(1.0)
        
        logger.info("ê°ì§€ ë£¨í”„ ì¢…ë£Œ")
    
    def get_latest_detection(self) -> Optional[Dict[str, Any]]:
        """ìµœì‹  ê°ì§€ ê²°ê³¼ ë°˜í™˜"""
        try:
            return self.detection_queue.get_nowait()
        except queue.Empty:
            return None
    
    def get_performance_info(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ì •ë³´ ë°˜í™˜"""
        elapsed_time = time.time() - self.start_time
        overall_fps = self.total_frames / elapsed_time if elapsed_time > 0 else 0
        
        info = {
            'overall_fps': overall_fps,
            'total_frames': self.total_frames,
            'elapsed_time': elapsed_time,
            'camera_fps': self.camera_manager.get_fps(),
            'is_running': self.is_running
        }
        
        # YOLO ì„±ëŠ¥ ì •ë³´ ì¶”ê°€
        info.update(self.yolo_detector.get_performance_info())
        
        return info
    
    # Context Manager ì§€ì›
    def __enter__(self):
        self.start()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.stop()

# ========== í—¬í¼ í•¨ìˆ˜ë“¤ ==========

def draw_detections(image: np.ndarray, objects: List[DetectedObject]) -> np.ndarray:
    """ê°ì§€ ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°"""
    result_image = image.copy()
    
    for obj in objects:
        # ë°”ìš´ë”© ë°•ìŠ¤
        x1, y1, x2, y2 = obj.bbox
        cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        
        # ì¤‘ì‹¬ì 
        cv2.circle(result_image, obj.center, 5, (0, 0, 255), -1)
        
        # ë¼ë²¨
        label = f"{obj.class_name}: {obj.confidence:.2f}"
        if obj.id is not None:
            label += f" (ID: {obj.id})"
        
        cv2.putText(result_image, label, (x1, y1 - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
    return result_image

def save_detection_results(objects: List[DetectedObject], filename: str):
    """ê°ì§€ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    try:
        import json
        data = [obj.to_dict() for obj in objects]
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ê°ì§€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
        
    except Exception as e:
        logger.error(f"ê°ì§€ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

# ========== í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ==========

def test_yolo_system():
    """YOLO ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª YOLO ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        with VisionSystem() as vision:
            print("âœ… ë¹„ì „ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì„±ê³µ")
            
            # ëª‡ ì´ˆê°„ ì‹¤í–‰
            time.sleep(3.0)
            
            # ì„±ëŠ¥ ì •ë³´ í™•ì¸
            perf_info = vision.get_performance_info()
            print(f"âœ… ì„±ëŠ¥ ì •ë³´: FPS={perf_info['overall_fps']:.1f}, "
                  f"í”„ë ˆì„={perf_info['total_frames']}")
            
            # ìµœì‹  ê°ì§€ ê²°ê³¼ í™•ì¸
            latest = vision.get_latest_detection()
            if latest:
                print(f"âœ… ê°ì§€ëœ ê°ì²´ ìˆ˜: {len(latest['objects'])}")
            
        print("âœ… YOLO ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ YOLO ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_yolo_system()
